{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d539490",
   "metadata": {},
   "source": [
    "# 2. Data Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e005258",
   "metadata": {},
   "source": [
    "Now that we have filtered out outliers and have made sanity checks on the dataset, we can split the dataset into train, test and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdaffde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedGroupKFold, GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fa561a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"cleaned_trajectories.csv\", index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5aa33e",
   "metadata": {},
   "source": [
    "Dataset details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc6cd679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique aircraft: 803\n",
      "Data length: 4175022\n",
      "Data length by 30s windows: 139167\n",
      "Data length by 60s windows: 69583\n",
      "Data length by 120s windows: 34791\n",
      "\n",
      "---------------\n",
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4175022 entries, 0 to 4175021\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count    Dtype  \n",
      "---  ------         --------------    -----  \n",
      " 0   timestamp      4175022 non-null  object \n",
      " 1   altitude       4175022 non-null  float64\n",
      " 2   flight_id      4175022 non-null  object \n",
      " 3   groundspeed    4175022 non-null  float64\n",
      " 4   latitude       4175022 non-null  float64\n",
      " 5   longitude      4175022 non-null  float64\n",
      " 6   track          4175022 non-null  float64\n",
      " 7   vertical_rate  4175022 non-null  float64\n",
      " 8   is_7700        4175022 non-null  bool   \n",
      "dtypes: bool(1), float64(6), object(2)\n",
      "memory usage: 258.8+ MB\n",
      "None\n",
      "\n",
      "---------------\n",
      "Dataset na percentages:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "timestamp        0.0\n",
       "altitude         0.0\n",
       "flight_id        0.0\n",
       "groundspeed      0.0\n",
       "latitude         0.0\n",
       "longitude        0.0\n",
       "track            0.0\n",
       "vertical_rate    0.0\n",
       "is_7700          0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Any na values in dataset: False\n",
      "\n",
      "---------------\n",
      "Unique flight ids: 803\n",
      "\n",
      "---------------\n",
      "Exact duplicate rows: 0\n",
      "\n",
      "---------------\n",
      "Number of 7700 squawks: 1214765, percent: 29.10%\n",
      "Number of flights that have the squawk: 803, percent: 100.00%\n"
     ]
    }
   ],
   "source": [
    "def dataset_details(df: pd.DataFrame) -> None:\n",
    "    print(f\"Number of unique aircraft: {df['flight_id'].nunique()}\")\n",
    "    print(f\"Data length: {len(df)}\")\n",
    "    print(f\"Data length by 30s windows: {len(df) // 30}\")\n",
    "    print(f\"Data length by 60s windows: {len(df) // 60}\")\n",
    "    print(f\"Data length by 120s windows: {len(df) // 120}\")\n",
    "\n",
    "    print(\"\\n\" + 15 * \"-\")\n",
    "    print(\"Dataset info:\")\n",
    "    print(df.info(show_counts=True))\n",
    "\n",
    "    print(\"\\n\" + 15 * \"-\")\n",
    "    print(\"Dataset na percentages:\")\n",
    "    na_pct = df.isna().mean().sort_values(ascending=False) * 100\n",
    "    display(na_pct)\n",
    "    print(\"Any na values in dataset:\", df.isna().values.any())\n",
    "\n",
    "    print(\"\\n\" + 15 * \"-\")\n",
    "    print(f\"Unique flight ids: {df['flight_id'].nunique()}\")\n",
    "\n",
    "    print(\"\\n\" + 15 * \"-\")\n",
    "    dupes = df.duplicated(subset=[\"flight_id\", \"timestamp\"])\n",
    "    print(\"Exact duplicate rows:\", dupes.sum())\n",
    "\n",
    "    print(\"\\n\" + 15 * \"-\")\n",
    "    print(\n",
    "        f\"Number of 7700 squawks: {df['is_7700'].sum()}, percent: {df['is_7700'].sum()/len(df)*100:.2f}%\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Number of flights that have the squawk: {df[df['is_7700']].flight_id.nunique()}, percent: {df[df['is_7700']].flight_id.nunique()/df['flight_id'].nunique()*100:.2f}%\"\n",
    "    )\n",
    "\n",
    "\n",
    "dataset_details(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e9d2ce",
   "metadata": {},
   "source": [
    "## Splitting options\n",
    "- Flight Group\n",
    "- Individual points (after window transformation)\n",
    "\n",
    "Splitting by individual points (row-wise) introduces the risk of data-leakage, does not generalise to real-world scenarios and breaks the temporal correlation as adjacent rows are split apart.\n",
    "\n",
    "\n",
    "On the other side, the split by flight group (**flight_id**) has zero risk in data-leakage, is conservative and realistic as the model can be deployed for future aircraft and preserves temporal correlation within each split (windows keep their chronology).\n",
    "\n",
    "Moreover, for sequence taks, group-wise splitting is the standard.\n",
    "\n",
    "The following split will be used:\n",
    "- Train: 70% (approx. 562 flights)\n",
    "- Validation: 15% (approx. 120 flights)\n",
    "- Test: 15% (approx. 121 flights)\n",
    "\n",
    "As seen in the dataset information, every single aircraft has at least **one 7700 row** (29% of all rows/windows), but the *ratio per flight* still varies.  \n",
    "\n",
    "To address this matter, we will:\n",
    "1. Compute per-flight emergency ratio;\n",
    "2. Define emergency-rate bins for stratification\n",
    "- We will use buckets which become a coarse \"class\" for emergency-share, so that when we split we preserve the overall distribution of **low-, mid-, and high-emergency flights**.\n",
    "3. Split the data by ensuring all windows of any given **flight_id** stay together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fad030f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flight_id</th>\n",
       "      <th>emg_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAL110_20190528</td>\n",
       "      <td>0.450440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAL1188_20190520</td>\n",
       "      <td>0.347334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          flight_id  emg_ratio\n",
       "0   AAL110_20190528   0.450440\n",
       "1  AAL1188_20190520   0.347334"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights = (\n",
    "    df.groupby(\"flight_id\")[\"is_7700\"]\n",
    "    .mean()  # emergency share for that flight\n",
    "    .reset_index()\n",
    "    .rename(columns={\"is_7700\": \"emg_ratio\"})\n",
    ")\n",
    "flights.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46c5d3b",
   "metadata": {},
   "source": [
    "Bin the per-flight emergency ratio into 4 buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ca96014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      2\n",
       "      ..\n",
       "798    1\n",
       "799    3\n",
       "800    1\n",
       "801    1\n",
       "802    1\n",
       "Name: emg_ratio, Length: 803, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins = pd.cut(\n",
    "    flights[\"emg_ratio\"],\n",
    "    bins=[0, 0.05, 0.5, 0.95, 1],\n",
    "    labels=False,\n",
    "    include_lowest=True,\n",
    ")\n",
    "bins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c460ee",
   "metadata": {},
   "source": [
    "Stratified split by those bins while repsecting the flight_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48a60cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgkf = StratifiedGroupKFold(\n",
    "    n_splits=5, shuffle=True, random_state=25\n",
    ")  # 4/5 flights in train\n",
    "train_idx, temp_idx = next(sgkf.split(X=flights, y=bins, groups=flights[\"flight_id\"]))\n",
    "\n",
    "train_flights = flights.iloc[train_idx][\"flight_id\"]\n",
    "temp_flights = flights.iloc[temp_idx][\"flight_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea6d8273",
   "metadata": {},
   "outputs": [],
   "source": [
    "gss = GroupShuffleSplit(test_size=0.5, n_splits=1, random_state=25)\n",
    "val_idx, test_idx = next(gss.split(temp_flights, groups=temp_flights))\n",
    "val_flights = temp_flights.iloc[val_idx]\n",
    "test_flights = temp_flights.iloc[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a773257",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[df[\"flight_id\"].isin(train_flights)]\n",
    "val_df = df[df[\"flight_id\"].isin(val_flights)]\n",
    "test_df = df[df[\"flight_id\"].isin(test_flights)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecbb6f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5      AAL1630_20190415\n",
       "10     AAL1895_20190708\n",
       "15      AAL213_20180603\n",
       "27     AAL2807_20180428\n",
       "46      AAR762_20190807\n",
       "             ...       \n",
       "775    VLG3866_20190913\n",
       "781     VOZ721_20200112\n",
       "786    WEN3410_20191123\n",
       "791     WJA439_20180904\n",
       "797     WOW699_20180125\n",
       "Name: flight_id, Length: 80, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2d0bb72d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split details: (percentages of flights - by flight_id): Train 0.8007, Val 0.0996, Test 0.0996\n",
      "Split details: (percentage of split - by rows): Train 0.7993, Val 0.1037, Test 0.0970\n",
      "Numer of train flights: 643, share of emergency rows: 0.2904\n",
      "Numer of val flights: 80, share of emergency rows: 0.2779\n",
      "Numer of test flights: 80, share of emergency rows: 0.3099\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Split details: (percentages of flights - by flight_id): Train {len(train_flights)/len(flights):.4f}, Val {len(val_flights)/len(flights):.4f}, Test {len(test_flights)/len(flights):.4f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Split details: (percentage of split - by rows): Train {len(train_df)/len(df):.4f}, Val {len(val_df)/len(df):.4f}, Test {len(test_df)/len(df):.4f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Numer of train flights: {len(train_flights)}, share of emergency rows: {train_df['is_7700'].sum()/len(train_df):.4f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Numer of val flights: {len(val_flights)}, share of emergency rows: {val_df['is_7700'].sum()/len(val_df):.4f}\"\n",
    ")\n",
    "print(\n",
    "    f\"Numer of test flights: {len(test_flights)}, share of emergency rows: {test_df['is_7700'].sum()/len(test_df):.4f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711618d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "189a9d61",
   "metadata": {},
   "source": [
    "Check for the correctness of the split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325942b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_train_flights = train_df[\"flight_id\"].unique()\n",
    "check_val_flights = val_df[\"flight_id\"].unique()\n",
    "check_test_flights = test_df[\"flight_id\"].unique()\n",
    "\n",
    "for ff in check_train_flights:\n",
    "    if ff in check_val_flights:\n",
    "        print(f\"Train flight {ff} is also in val set\")\n",
    "    if ff in check_test_flights:\n",
    "        print(f\"Train flight {ff} is also in test set\")\n",
    "\n",
    "for ff in check_val_flights:\n",
    "    if ff in check_train_flights:\n",
    "        print(f\"Val flight {ff} is also in train set\")\n",
    "    if ff in check_test_flights:\n",
    "        print(f\"Val flight {ff} is also in test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3d345218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, val, and test sets saved to data_splits/ folder.\n"
     ]
    }
   ],
   "source": [
    "data_split_folder = \"data_splits/\"\n",
    "train_df.to_csv(data_split_folder + \"train.csv\", index=False)\n",
    "val_df.to_csv(data_split_folder + \"val.csv\", index=False)\n",
    "test_df.to_csv(data_split_folder + \"test.csv\", index=False)\n",
    "print(f\"Train, val, and test sets saved to {data_split_folder} folder.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
